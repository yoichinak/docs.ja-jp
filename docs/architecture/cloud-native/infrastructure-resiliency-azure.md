---
title: Azure platform の回復性
description: Azure 向けのクラウドネイティブ .NET アプリの設計 |Azure を使用したクラウドインフラストラクチャの回復性
ms.date: 06/30/2019
ms.openlocfilehash: 02d661952c860da25442b0fa9fed0d5f93abe023
ms.sourcegitcommit: 4f4a32a5c16a75724920fa9627c59985c41e173c
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/17/2019
ms.locfileid: "73841259"
---
# <a name="azure-platform-resiliency"></a>Azure platform の回復性

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

クラウドで信頼性の高いアプリケーションを構築することは、従来のオンプレミスアプリケーションの開発とは異なります。 これまでは、スケールアウトするクラウド環境でハイエンドのハードウェアを購入しましたが、障害を防ぐのではなく、その影響を最小限に抑え、システムの安定性を維持することを目標としています。

しかし、信頼性の高いクラウドアプリケーションでは、次のように異なる特性が表示されます。

- これらは回復力があり、問題から適切に回復し、引き続き機能します。
- 高可用性 (HA) で、非常に長いダウンタイムなしで正常な状態で設計されているように実行されます。

これらの特性がどのように連携するか、およびそれらがコストにどのように影響するかを理解することは、信頼性の高いクラウドネイティブアプリケーションを構築するために不可欠です。 次に、Azure クラウドの機能を利用して、クラウドネイティブアプリケーションに回復性と可用性を構築する方法について見ていきます。

## <a name="design-with-redundancy"></a>冗長性を備えた設計

障害は影響の範囲によって異なります。 障害が発生したディスクなどのハードウェア障害は、クラスター内の1つのノードに影響を与える可能性があります。 ネットワークスイッチの障害は、サーバーラック全体に影響を与える可能性があります。 電力の損失など、一般的ではない障害により、データセンター全体が混乱する可能性があります。 ほとんどの場合、リージョン全体が使用できなくなります。

[冗長性](https://docs.microsoft.com/azure/architecture/guide/design-principles/redundancy)は、アプリケーションの回復力を提供する1つの方法です。 必要な冗長性の正確なレベルは、ビジネス要件によって異なり、システムのコストと複雑さの両方に影響します。 たとえば、複数リージョンのデプロイは、単一リージョンのデプロイよりもコストが高く、複雑になります。 フェールオーバーとフェールバックを管理するには、運用手順が必要です。 追加コストと複雑さは、ビジネスシナリオによっては正当化されない場合があります。

冗長性を設計するには、アプリケーションで重要なパスを特定し、パスの各ポイントに冗長性があるかどうかを確認する必要があります。 サブシステムで障害が発生した場合、アプリケーションは何かにフェールオーバーしますか。 最後に、冗長性の要件を満たすために利用できる、Azure クラウドプラットフォームに組み込まれている機能を明確に理解する必要があります。 冗長性を設計するための推奨事項を次に示します。

- *サービスの複数のインスタンスをデプロイします。* アプリケーションがサービスの1つのインスタンスに依存している場合は、単一障害点が発生します。 複数のインスタンスをプロビジョニングすると、回復性とスケーラビリティが向上します。 Azure Kubernetes Service でホストする場合は、Kubernetes マニフェストファイル内の冗長インスタンス (レプリカセット) を宣言によって構成できます。 レプリカ数の値は、プログラム、ポータル、または自動スケール機能を使用して管理できます。これについては後で説明します。

- *ロードバランサーを活用する。* 負荷分散は、アプリケーションの要求を正常なサービスインスタンスに分散し、異常なインスタンスをローテーションから自動的に削除します。 Kubernetes にデプロイする場合は、[サービス] セクションの Kubernetes マニフェストファイルで負荷分散を指定できます。

- *複数リージョンのデプロイを計画します。* アプリケーションが1つのリージョンにデプロイされていて、そのリージョンが使用できなくなった場合は、アプリケーションも使用できなくなります。 これは、アプリケーションのサービスレベルアグリーメントの条項によっては受け入れられない可能性があります。 代わりに、アプリケーションとそのサービスを複数のリージョンにデプロイすることを検討してください。 たとえば、Azure Kubernetes Service (AKS) クラスターは1つのリージョンにデプロイされます。 リージョン内の障害からシステムを保護するには、異なるリージョンの複数の AKS クラスターにアプリケーションをデプロイし、[ペアのリージョン](https://buildazure.com/2017/01/06/azure-region-pairs-explained/)機能を使用してプラットフォームの更新を調整し、復旧作業の優先順位を設定します。

- *[Geo レプリケーション](https://docs.microsoft.com/azure/sql-database/sql-database-active-geo-replication)を有効にします。* Azure SQL Database や Cosmos DB などのサービスの Geo レプリケーションでは、複数のリージョンにわたってデータのセカンダリレプリカが作成されます。 どちらのサービスも同じリージョン内のデータを自動的にレプリケートしますが、geo レプリケーションでは、セカンダリリージョンへのフェールオーバーを可能にすることで、リージョンの停止を防ぐことができます。 コンテナーイメージの格納に関するその他のベストプラクティスとして、geo レプリケーションを使用することをお勧めします。 AKS でサービスをデプロイするには、リポジトリからイメージを格納してプルする必要があります。 Azure Container Registry は AKS と統合され、コンテナーイメージを安全に格納できます。 パフォーマンスと可用性を向上させるには、AKS クラスターがある各リージョンのレジストリにイメージを geo レプリケートすることを検討してください。 次に図6-6 に示すように、各 AKS クラスターは、そのリージョンのローカルコンテナーレジストリからコンテナーイメージをプルします。

![リージョン間でレプリケートされたリソース](./media/replicated-resources.png)

**図 6-6**。 リージョン間でレプリケートされたリソース

- *DNS トラフィックのロードバランサーを実装します。* [Azure Traffic Manager](https://docs.microsoft.com/azure/traffic-manager/traffic-manager-overview)は、DNS レベルで負荷分散を行うことによって、重要なアプリケーションに高可用性を提供します。 地理的、クラスターの応答時間、さらにはアプリケーションエンドポイントの正常性に基づいて、異なるリージョンにトラフィックをルーティングすることができます。 たとえば、Azure Traffic Manager では、最も近い AKS クラスターとアプリケーションインスタンスに顧客を誘導できます。 異なるリージョンに複数の AKS クラスターがある場合は、Traffic Manager を使用して、各クラスターで実行されるアプリケーションへのトラフィックフローを制御します。 図6-7 はこのシナリオを示しています。

![AKS と Azure Traffic Manager](./media/aks-traffic-manager.png)

**図 6-7**。 AKS と Azure Traffic Manager

## <a name="design-for-scalability"></a>スケーラビリティのための設計

クラウドの thrives をスケーリングします。 システムの負荷の増加と減少に対処するために、システムリソースを増減する機能は、Azure クラウドの重要な理念です。 しかし、アプリケーションを効果的にスケーリングするには、アプリケーションに含める各 Azure サービスのスケーリング機能について理解しておく必要があります。  ここでは、システムにスケーリングを効果的に実装するための推奨事項を示します。

- *スケーリングのための設計。* アプリケーションは、スケーリング用に設計する必要があります。 開始するには、サービスがステートレスである必要があります。これにより、任意のインスタンスに要求をルーティングできます。 また、ステートレスサービスを用意すると、インスタンスを追加または削除しても現在のユーザーに悪影響を及ぼすことはありません。

- *ワークロードをパーティション分割*します。 ドメインを独立した自己完結型マイクロサービスに分解することにより、各サービスを他のサービスとは無関係に拡張できます。 通常、サービスにはさまざまなスケーラビリティニーズと要件があります。 パーティション分割を使用すると、アプリケーション全体のスケーリングに不要なコストをかけることなく、スケーリングする必要があるものだけをスケールできます。

- *スケールアウトを優先します。* クラウドベースのアプリケーションでは、スケールアップではなく、リソースのスケールアウトが優先されます。 スケールアウト (水平スケーリングとも呼ばれます) では、必要なレベルのパフォーマンスを満たして共有するために、既存のシステムにサービスリソースを追加します。 スケールアップ (垂直スケーリングとも呼ばれます) では、既存のリソースをより強力なハードウェア (より多くのディスク、メモリ、および処理コア) に置き換える必要があります。 スケールアウトは、一部の Azure クラウドリソースで使用可能な自動スケール機能を使用して自動的に呼び出すことができます。 複数のリソースをスケールアウトすると、システム全体に冗長性も追加されます。 最終的には、1つのリソースをスケールアップすることは、多くの小さなリソースに対してスケールアウトするよりもコストが高くなります。 図6-8 は、次の2つの方法を示しています。

![スケールアップとスケールアウト](./media/scale-up-scale-out.png)

**図 6-8.** スケールアップとスケールアウト

- *比例してスケーリングします。* サービスをスケーリングする場合は、*リソースセット*を考慮してください。 特定のサービスを劇的にスケールアウトする場合、バックエンドのデータストア、キャッシュ、および依存サービスに対する影響はどのようなものですか。 Cosmos DB などの一部のリソースは、比例してスケールアウトできますが、他のリソースは使用できません。 リソースをスケールアウトしないようにして、関連する他のリソースを消費しないようにする必要があります。

- *アフィニティを回避します。* ノードがローカルアフィニティを必要としないようにすることをお勧めします。これは、多くの場合、*固定セッション*と呼ばれます。 要求は、任意のインスタンスにルーティングできなければなりません。 状態を永続化する必要がある場合は、 [Azure Redis cache](https://azure.microsoft.com/services/cache/)などの分散キャッシュに保存する必要があります。

- *プラットフォームの自動スケール機能を活用します。* 組み込みの自動スケール機能は、カスタムまたはサードパーティのメカニズムではなく、可能な限り使用してください。 可能であれば、スケジュールされたスケーリングルールを使用して、起動の遅延なしにリソースが使用可能であることを確認します。ただし、必要に応じて、予期しない変更が発生した場合に備えてルールにリアクティブな自動スケールを追加します。 詳細については、「自動[スケールガイダンス](https://docs.microsoft.com/azure/architecture/best-practices/auto-scaling)」を参照してください。

- *積極的にスケールアウトします。* 最終的には、ビジネスを失うことなく迅速にトラフィックの急増に対応できるように、積極的にスケールアウトする必要があります。 また、システムを安定した状態に保つために、スケールイン (不要なインスタンスを削除する) 控えめします。 これを実装する簡単な方法は、クールダウン期間を設定することです。これは、スケーリング操作の間の待機時間であり、リソースを追加する場合は5分、インスタンスを削除する場合は最大15分です。

## <a name="built-in-retry-in-services"></a>サービスでの組み込みの再試行

前のセクションでは、プログラムによる再試行操作を実装することをお勧めします。 多くの Azure サービスとそれに対応するクライアント Sdk には、再試行メカニズムも含まれることに注意してください。 次の一覧は、このブックで説明されている多くの Azure サービスの再試行機能をまとめたものです。

- *Azure Cosmos DB。* クライアント API の <xref:Microsoft.Azure.Documents.Client.DocumentClient> クラスは、失敗した試行を自動的に廃止します。 再試行回数と最大待機時間は構成可能です。 クライアント API によってスローされる例外は、再試行ポリシーまたは一時的でないエラーを超える要求のいずれかです。

- *Azure Redis Cache。* Redis StackExchange クライアントは、失敗した試行に対する再試行を含む接続マネージャークラスを使用します。 再試行回数、特定の再試行ポリシー、待機時間はすべて構成可能です。

- *Azure Service Bus。* Service Bus クライアントは、バックオフ間隔、再試行回数、および <xref:Microsoft.ServiceBus.RetryExponential.TerminationTimeBuffer>で構成できる[RetryPolicy クラス](xref:Microsoft.ServiceBus.RetryPolicy)を公開します。このクラスは、操作が実行できる最大時間を指定します。 既定のポリシーは、30秒間のバックオフ期間による最大9回の再試行です。

- *Azure SQL Database。* [Entity Framework Core](https://docs.microsoft.com/ef/core/miscellaneous/connection-resiliency)ライブラリを使用する場合は、再試行のサポートが提供されます。

- *Azure Storage。* ストレージクライアントライブラリは再試行操作をサポートしています。 戦略は、Azure storage のテーブル、blob、キューによって異なります。 さらに、geo 冗長機能が有効になっている場合は、プライマリストレージサービスとセカンダリストレージサービスの場所が交互に再試行されます。

- *Azure Event Hubs。* イベントハブクライアントライブラリは、構成可能な指数バックオフ機能を含む RetryPolicy プロパティを特徴としています。

>[!div class="step-by-step"]
>[前へ](application-resiliency-patterns.md)
>[次へ](resilient-communications.md)
